{
 "cells": [
  {
    "cell_type": "markdown",
    "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
    },
    "source": [
        "<a href=\"https://colab.research.google.com/github/dragoa/MachineLearning/blob/main/NLP/Mistral%20AI/L2_prompting_capabilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
    ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8",
   "metadata": {},
   "source": [
    "# Prompting Capabilities \n",
    "\n",
    "- Note, you can try any of these prompts outside of this classroom, and without coding, by going to the chat interface [Le Chat](https://chat.mistral.ai/chat).\n",
    "  - You can sign up with a free account.\n",
    "  - Signing up for an account is **not** required to complete this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa37d97-10e4-425d-b852-15bd043662b9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mistralai\n",
      "  Downloading mistralai-0.1.8-py3-none-any.whl (15 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.10\n",
      "  Downloading orjson-3.10.1-cp39-none-win_amd64.whl (138 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.2\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Collecting httpx<0.26.0,>=0.25.2\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: sniffio in c:\\tools\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\tools\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2021.10.8)\n",
      "Requirement already satisfied: idna in c:\\tools\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.3)\n",
      "Requirement already satisfied: anyio in c:\\tools\\anaconda3\\lib\\site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.5.0)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.18.2\n",
      "  Downloading pydantic_core-2.18.2-cp39-none-win_amd64.whl (1.9 MB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: typing-extensions, h11, pydantic-core, httpcore, annotated-types, pydantic, orjson, httpx, mistralai\n",
      "Successfully installed annotated-types-0.6.0 h11-0.14.0 httpcore-1.0.5 httpx-0.25.2 mistralai-0.1.8 orjson-3.10.1 pydantic-2.7.1 pydantic-core-2.18.2 typing-extensions-4.11.0\n"
     ]
    }
   ],
   "source": [
    "%pip install mistralai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3ac64-1295-4a0e-90ab-51c338c945f7",
   "metadata": {},
   "source": [
    "- Notice that it's \"mistralai\", and not \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff393a84-303a-48ae-97fe-3551f524f733",
   "metadata": {},
   "source": [
    "### Load API key and helper function\n",
    "- Note: You can view or download the helper.py file by clicking on the \"Jupyter\" logo to access the file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6a5640-203a-4e7a-bc4c-4bfe78da4099",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from helper import load_mistral_api_key\n",
    "load_mistral_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016",
   "metadata": {
    "height": 47
   },
   "outputs": [{
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "'Hello! I can assist you with a variety of tasks such as answering questions, setting reminders, providing information on weather, news, sports, and more. I can also help you manage your schedule, find recipes, and even tell jokes. How can I assist you today?'"
    ]
   }],
   "source": [
    "from helper import mistral\n",
    "mistral(\"hello, what can you do?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a29ef-4764-40b7-aedload8-0e5d0502f985",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad",
   "metadata": {
    "height": 642
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a bank customer service bot. \n",
    "    Your task is to assess customer intent and categorize customer \n",
    "    inquiry after <<<>>> into one of the following predefined categories:\n",
    "    \n",
    "    card arrival\n",
    "    change pin\n",
    "    exchange rate\n",
    "    country support \n",
    "    cancel transfer\n",
    "    charge dispute\n",
    "    \n",
    "    If the text doesn't fit into any of the above categories, \n",
    "    classify it as:\n",
    "    customer service\n",
    "    \n",
    "    You will only respond with the predefined category. \n",
    "    Do not provide explanations or notes. \n",
    "    \n",
    "    ###\n",
    "    Here are some examples:\n",
    "    \n",
    "    Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
    "    Category: card arrival\n",
    "    Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
    "    Category: exchange rate \n",
    "    Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
    "    Category: country support\n",
    "    Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue. \n",
    "    Category: customer service\n",
    "    ###\n",
    "    \n",
    "    <<<\n",
    "    Inquiry: {inquiry}\n",
    "    >>>\n",
    "    Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d367f-cc2c-4857-abd5-d1f6a545ebc0",
   "metadata": {},
   "source": [
    "#### Ask Mistral to check the spelling and grammar of your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465a2ecd-e542-4863-96dc-29786c003799",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "response = mistral(f\"Please correct the spelling and grammar of \\\n",
    "this prompt and return a text that is the same prompt,\\\n",
    "with the spelling and grammar fixed: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476f0db5-ba51-43ca-a4c4-dc2b072291ba",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a bank customer service bot.\n",
      "Your task is to assess customer intent and categorize the customer inquiry following the inquiry into one of the following predefined categories:\n",
      "\n",
      "card arrival\n",
      "change PIN\n",
      "exchange rate\n",
      "country support\n",
      "cancel transfer\n",
      "charge dispute\n",
      "\n",
      "If the text does not fit into any of the above categories, classify it as:\n",
      "customer service\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "\n",
      "Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
      "Category: card arrival\n",
      "Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
      "Category: exchange rate\n",
      "Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
      "Category: country support\n",
      "Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue.\n",
      "Category: customer service\n",
      "###\n",
      "\n",
      "<<<\n",
      "Inquiry: {inquiry}\n",
      ">>>\n",
      "Category:"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bbf68-a0bc-4e8a-bb6b-8ae20f3f2e2d",
   "metadata": {},
   "source": [
    "#### Try out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4625fdc0-c6ef-4dcf-bbc0-d250a0ed277c",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'country support'"
     ]
    }
   ],
   "source": [
    "mistral(\n",
    "    response.format(\n",
    "        inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252e995-f3fc-4e62-abdb-3e367df55cbe",
   "metadata": {},
   "source": [
    "## Information Extraction with JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6741a613-5b1b-4fb1-9843-1c5737f36cd5",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "medical_notes = \"\"\"\n",
    "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
    "of increased thirst, frequent urination, fatigue, and unexplained\n",
    "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
    "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
    "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
    "with meals. It was noted during the consultation that the patient is\n",
    "a current smoker. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c2bd7a-48c9-4c0b-8a4a-049a43045805",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Extract information from the following medical notes:\n",
    "{medical_notes}\n",
    "\n",
    "Return json format with the following JSON schema: \n",
    "\n",
    "{{\n",
    "        \"age\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"gender\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"male\", \"female\", \"other\"]\n",
    "        }},\n",
    "        \"diagnosis\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
    "        }},\n",
    "        \"weight\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"smoking\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"yes\", \"no\"]\n",
    "        }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951a0b58-aae5-45e2-8496-714b884f16b6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "response = mistral(prompt, is_json=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9cb95-bb08-4929-b16c-eb19877f3c01",
   "metadata": {},
   "source": [
    "## Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf048b4-3e33-4753-af97-25b73c51ee6a",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"age\": 60, \"gender\": \"male\", \"diagnosis\": \"diabetes\", \"weight\": 210, \"smoking\": \"yes\"}"
     ]
    }
   ],
   "source": [
    "email = \"\"\"\n",
    "Dear mortgage lender, \n",
    "\n",
    "What's your 30-year fixed-rate APR, how is it compared to the 15-year \n",
    "fixed rate?\n",
    "\n",
    "Regards,\n",
    "Anna\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36de7c1e-60c2-4f35-a51a-115b12d65bb6",
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "You are a mortgage lender customer service bot, and your task is to \n",
    "create personalized email responses to address customer questions.\n",
    "Answer the customer's inquiry using the provided facts below. Ensure \n",
    "that your response is clear, concise, and directly addresses the \n",
    "customer's question. Address the customer in a friendly and \n",
    "professional manner. Sign the email with \"Lender Customer Support.\"   \n",
    "      \n",
    "# Facts\n",
    "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
    "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
    "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
    "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
    "7-year ARM: interest rate 7.011%, APR 7.660%\n",
    "5-year ARM: interest rate 6.880%, APR 7.754%\n",
    "3-year ARM: interest rate 6.125%, APR 7.204%\n",
    "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
    "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
    "\n",
    "# Email\n",
    "{email}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf50774-0f91-4e0e-86c9-1525f6045ebb",
   "metadata": {
    "height": 47,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Inquiry about 30-year and 15-year fixed-rate mortgage APRs\n",
      "Dear Anna,\n",
      "\n",
      "Thank you for reaching out to us with your inquiry about our mortgage rates. I'd be happy to provide you with the information you're looking for.\n",
      "\n",
      "For our 30-year fixed-rate mortgage, the Annual Percentage Rate (APR) is currently 6.484%. In comparison, the APR for our 15-year fixed-rate mortgage is 5.848%.\n",
      "\n",
      "The APR for the 15-year fixed-rate mortgage is lower than that of the 30-year fixed-rate mortgage. This is because the loan term is shorter, which means you would be paying off the loan in half the time, resulting in less interest accruing over the life of the loan. However, the monthly payments for the 15-year fixed-rate mortgage would be higher due to the loan being paid off in a shorter period of time.\n",
      "\n",
      "I hope this information helps in your decision-making process. If you have any other questions or if there's anything else I can assist you with, please don't hesitate to ask.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Lender Customer Support\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfaad2c-411e-4221-80f0-7acd21ba398c",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "- We'll use this [article](https://www.deeplearning.ai/the-batch/mistral-enhances-ai-landscape-in-europe-with-microsoft-partnership-and-new-language-models) from The Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bbab492-1d18-4832-86a9-2fba645e0e52",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "newsletter = \"\"\"\n",
    "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft. \n",
    "\n",
    "What’s new: Mistral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it agreed to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free here and to use on its La Plateforme and via custom deployments.\n",
    "\n",
    "Model specs: The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context. \n",
    "\n",
    "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.\n",
    "Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.\n",
    "Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion stake in OpenAI and Google and Amazon’s investments in Anthropic, which amount to $2 billion and $4 billion respectively.\n",
    "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
    "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission argued on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models. \n",
    "\n",
    "Yes, but: Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was investigating Microsoft’s agreement with OpenAI for potential breaches of antitrust law, plans to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party criticized the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
    "\n",
    "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.\n",
    "\n",
    "We’re thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaede63d-7392-4f1c-8a87-507ee31fe246",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a commentator. Your task is to write a report on a newsletter. \n",
    "When presented with the newsletter, come up with interesting questions to ask,\n",
    "and answer each question. \n",
    "Afterward, combine all the information and write a report in the markdown\n",
    "format. \n",
    "\n",
    "# Newsletter: \n",
    "{newsletter}\n",
    "\n",
    "# Instructions: \n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes \n",
    "presented in the newsletter.\n",
    "\n",
    "## Interesting Questions: \n",
    "Generate three distinct and thought-provoking questions that can be \n",
    "asked about the content of the newsletter. For each question:\n",
    "- After \"Q: \", describe the problem \n",
    "- After \"A: \", provide a detailed explanation of the problem addressed \n",
    "in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "\n",
    "## Write a analysis report\n",
    "Using the summary and the answers to the interesting questions, \n",
    "create a comprehensive report in Markdown format. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5505b0a5-411b-4804-aaef-ccecfa3d07be",
   "metadata": {
    "height": 47,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Summary\n",
      "\n",
      "Mistral AI, a European AI champion, has unveiled two new large language models: Mistral Large and Mistral Small. Microsoft has invested $16.3 million in the French startup and formed an alliance to distribute Mistral Large on its Azure platform and allow Mistral AI to use Azure's computing infrastructure. The new models outperform some of their competitors on the MMLU benchmark, and both are fluent in multiple languages. However, the partnership has stirred controversy among European lawmakers and regulators due to potential antitrust breaches and data privacy concerns.\n",
      "\n",
      "# Interesting Questions\n",
      "\n",
      "Q: How do the new Mistral models compare to other large language models in terms of performance and capabilities?\n",
      "A: The new models have been benchmarked against several other large language models. Mistral Large outperformed Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B on the MMLU benchmark, but did not surpass GPT-4. Both models are fluent in French, German, Spanish, and Italian, and are trained for function calling and JSON-format output. However, specific details about the models' parameter counts, architectures, and training methods have not been disclosed.\n",
      "\n",
      "<Mistral Large outperforms several competitors on the MMLU benchmark, and both models are multilingual and trained for function calling.>\n",
      "\n",
      "Q: What are the potential implications and controversies surrounding the partnership between Mistral AI and Microsoft?\n",
      "A: The partnership has raised concerns among European lawmakers and regulators. The European Commission is investigating the partnership for potential breaches of antitrust law, as it is already investigating Microsoft’s agreement with OpenAI for the same reason. Some members of President Emmanuel Macron’s Renaissance party have criticized the deal for potentially giving a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
      "\n",
      "<The partnership has stirred controversy due to potential antitrust breaches and data privacy concerns.>\n",
      "\n",
      "Q: What benefits does this partnership bring to Mistral AI, Microsoft, and their customers?\n",
      "A: The partnership provides Mistral AI with crucial processing power for training large models and greater access to potential customers worldwide. It gives Microsoft greater access to the European market and provides Azure customers with a high-performance model tailored to Europe’s unique regulatory environment.\n",
      "\n",
      "<The partnership gives Mistral AI crucial processing power, Microsoft greater European market access, and Azure customers a high-performance, Europe-tailored model.>\n",
      "\n",
      "# Analysis Report\n",
      "\n",
      "## Mistral AI Unveils New Large Language Models and Forms Alliance with Microsoft\n",
      "\n",
      "Mistral AI, a leading European AI startup, has introduced two new large language models: Mistral Large and Mistral Small. These models join the previously released Mistral Medium, which was quietly launched late last year. In addition to this, Mistral AI has formed a strategic alliance with Microsoft, which has invested $16.3 million in the French startup.\n",
      "\n",
      "### Performance and Capabilities of the New Models\n",
      "\n",
      "The new models have been benchmarked against several other large language models. Mistral Large outperformed Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B on the MMLU benchmark, but did not surpass GPT-4. Both models are fluent in French, German, Spanish, and Italian, and are trained for function calling and JSON-format output. However, specific details about the models' parameter counts, architectures, and training methods have not been disclosed.\n",
      "\n",
      "### Implications and Controversies of the Partnership\n",
      "\n",
      "The partnership between Mistral AI and Microsoft has sparked controversy among European lawmakers and regulators. The European Commission is investigating the partnership for potential breaches of antitrust law, as it is already investigating Microsoft’s agreement with OpenAI for the same reason. Some members of President Emmanuel Macron’s Renaissance party have criticized the deal for potentially giving a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
      "\n",
      "### Benefits of the Partnership\n",
      "\n",
      "The partnership provides Mistral AI with crucial processing power for training large models and greater access to potential customers worldwide. It gives Microsoft greater access to the European market and provides Azure customers with a high-performance model tailored to Europe’s unique regulatory environment.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Mistral AI has made significant strides in the AI field, particularly given its status as a startup. Its partnership with Microsoft, a leading hyperscaler, underscores the considerable processing and distribution power still concentrated in large, U.S.-based cloud companies. While the partnership has stirred controversy, it promises to bring significant benefits to all parties involved."
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6590c2-2558-45be-84cb-b1b99dbc3776",
   "metadata": {},
   "source": [
    "#### Try it out for yourself\n",
    "- Feel free to copy-paste text from another article in The Batch, or any other blog or news article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed88147-8d43-4207-b45b-06543371f913",
   "metadata": {},
   "source": [
    "## The Mistral Python client\n",
    "- Below is the helper function that you imported from helper.py and used earlier in this notebook.\n",
    "- For more details, check out the [Mistral AI API documentation](https://docs.mistral.ai/api/)\n",
    "- To get your own Mistral AI API key to use on your own, outside of this classroom, you can create an account and go to the [console](https://console.mistral.ai/) to subscribe and create an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27ef7a7f-ebd6-49c3-8f91-5f5d284edf17",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage   \n",
    "\n",
    "def mistral(user_message, \n",
    "            model=\"mistral-small-latest\",\n",
    "            is_json=False):\n",
    "    client = MistralClient(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"})\n",
    "    else:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages)\n",
    "        \n",
    "    return chat_response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
