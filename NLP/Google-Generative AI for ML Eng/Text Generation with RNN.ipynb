{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Generate text using a character based RNN. Given a sequence of chars, train an RNN model to predict the most\n",
    "probable next char in the sequence.\n",
    "\n",
    "While some of the sentences are grammatical, most do not make sense. The model has not learned the meaning of words, but here are some things to consider:\n",
    "- The model is character-based. When training started, the model did not know how to spell an English word, or that words were even a unit of text.\n",
    "- The structure of the output resembles a play—blocks of text generally begin with a speaker name, in all capital letters similar to the dataset.\n",
    "- As demonstrated below, the model is trained on small batches of text (100 characters each), and is still able to generate a longer sequence of text with coherent structure."
   ],
   "id": "26ddb515c38d1971"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T20:31:16.135181Z",
     "start_time": "2025-04-01T20:31:16.131853Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Download the Shakespeare dataset.",
   "id": "b9105e94378d57d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:31:19.138907Z",
     "start_time": "2025-04-01T20:31:18.000145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = tf.keras.utils.get_file(\n",
    "    \"shakespeare.txt\",\n",
    "    origin=\"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",
    ")"
   ],
   "id": "35a557b6cf4149de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "\u001B[1m1115394/1115394\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1us/step\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:33:59.697430Z",
     "start_time": "2025-04-01T20:33:59.685516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = open(path, \"rb\").read().decode(encoding='utf-8')\n",
    "print(len(text))\n",
    "# print first 250 chars\n",
    "print(text[:250])"
   ],
   "id": "32a9ae8b6acc211e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check to see how many unique characters are in our corpus/document.",
   "id": "af758bc4fbd25295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T20:35:53.603385Z",
     "start_time": "2025-04-01T20:35:53.587801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f\"Number of unique chars: {len(vocab)}\")"
   ],
   "id": "d1fed0227fe92d06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique chars: 65\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Process the text\n",
    "### Vectorize the text\n",
    "Before training, you need to convert the strings to a numerical representation.\n",
    "\n",
    "Using tf.keras.layers.StringLookup layer can convert each character into a numeric ID. It just needs the text to be split into tokens first."
   ],
   "id": "85a7f9385d548d2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "850a9e55197446e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
