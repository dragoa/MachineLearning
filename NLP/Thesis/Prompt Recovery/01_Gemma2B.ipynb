{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b540286f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:17.799983Z",
     "iopub.status.busy": "2024-08-27T21:43:17.799212Z",
     "iopub.status.idle": "2024-08-27T21:43:18.504771Z",
     "shell.execute_reply": "2024-08-27T21:43:18.503988Z"
    },
    "papermill": {
     "duration": 0.715479,
     "end_time": "2024-08-27T21:43:18.507341",
     "exception": false,
     "start_time": "2024-08-27T21:43:17.791862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae15ae8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:18.519949Z",
     "iopub.status.busy": "2024-08-27T21:43:18.519622Z",
     "iopub.status.idle": "2024-08-27T21:43:18.782173Z",
     "shell.execute_reply": "2024-08-27T21:43:18.781131Z"
    },
    "papermill": {
     "duration": 0.271643,
     "end_time": "2024-08-27T21:43:18.784964",
     "exception": false,
     "start_time": "2024-08-27T21:43:18.513321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the generated ground truth\n",
    "test = pd.read_csv('/kaggle/input/llm-prompt-recovery-ground-truth/test.csv')\n",
    "test.head()\n",
    "test = test.head(195)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfbada",
   "metadata": {
    "papermill": {
     "duration": 0.005336,
     "end_time": "2024-08-27T21:43:18.796162",
     "exception": false,
     "start_time": "2024-08-27T21:43:18.790826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predictions \n",
    "Predictions of the prompt using a finetuned keras version of Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01632c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:18.808172Z",
     "iopub.status.busy": "2024-08-27T21:43:18.807871Z",
     "iopub.status.idle": "2024-08-27T21:43:22.422385Z",
     "shell.execute_reply": "2024-08-27T21:43:22.421429Z"
    },
    "papermill": {
     "duration": 3.623642,
     "end_time": "2024-08-27T21:43:22.425094",
     "exception": false,
     "start_time": "2024-08-27T21:43:18.801452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"0.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcf0e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:22.438213Z",
     "iopub.status.busy": "2024-08-27T21:43:22.437848Z",
     "iopub.status.idle": "2024-08-27T21:43:35.289942Z",
     "shell.execute_reply": "2024-08-27T21:43:35.288555Z"
    },
    "papermill": {
     "duration": 12.861592,
     "end_time": "2024-08-27T21:43:35.292559",
     "exception": false,
     "start_time": "2024-08-27T21:43:22.430967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 21:43:26.355051: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-27 21:43:26.355156: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-27 21:43:26.478739: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bcda73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:35.307061Z",
     "iopub.status.busy": "2024-08-27T21:43:35.306493Z",
     "iopub.status.idle": "2024-08-27T21:43:35.700020Z",
     "shell.execute_reply": "2024-08-27T21:43:35.699102Z"
    },
    "papermill": {
     "duration": 0.403039,
     "end_time": "2024-08-27T21:43:35.702093",
     "exception": false,
     "start_time": "2024-08-27T21:43:35.299054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0), cuda(id=1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gpu:0', 'gpu:1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import os\n",
    "\n",
    "# The Keras 3 distribution API is only implemented for the JAX backend for now\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation overhead\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\"\n",
    "\n",
    "print(jax.devices())\n",
    "\n",
    "import keras\n",
    "keras.distribution.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060c28c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:35.715862Z",
     "iopub.status.busy": "2024-08-27T21:43:35.715544Z",
     "iopub.status.idle": "2024-08-27T21:43:35.724520Z",
     "shell.execute_reply": "2024-08-27T21:43:35.723587Z"
    },
    "papermill": {
     "duration": 0.018042,
     "end_time": "2024-08-27T21:43:35.726573",
     "exception": false,
     "start_time": "2024-08-27T21:43:35.708531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeviceMesh shape=(1, 2), axis_names=['batch', 'model']>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from tensorflow import data as tf_data  # For dataset input.\n",
    "\n",
    "num_gpu=len(keras.distribution.list_devices())\n",
    "# there are 2 cudas in TPU T4x2 - VMv3-8 has 8\n",
    "gpu_mesh = keras.distribution.DeviceMesh(\n",
    "    shape=(1,num_gpu),\n",
    "    axis_names=[\"batch\", \"model\"], \n",
    "    devices=keras.distribution.list_devices()\n",
    ")\n",
    "gpu_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f730c71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:35.739803Z",
     "iopub.status.busy": "2024-08-27T21:43:35.739533Z",
     "iopub.status.idle": "2024-08-27T21:43:35.745414Z",
     "shell.execute_reply": "2024-08-27T21:43:35.744522Z"
    },
    "papermill": {
     "duration": 0.014676,
     "end_time": "2024-08-27T21:43:35.747422",
     "exception": false,
     "start_time": "2024-08-27T21:43:35.732746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a LayoutMap instance\n",
    "layout = keras.distribution.LayoutMap(device_mesh=gpu_mesh)\n",
    "\n",
    "layout[\"token_embedding/embeddings\"] = (None, \"model\")\n",
    "layout[\"decoder_block.*attention.*(query|key|value).*kernel\"] = (None, \"model\", None)\n",
    "layout[\"decoder_block.*attention_output.*kernel\"] = (None, None, \"model\")\n",
    "layout[\"decoder_block.*ffw_gating.*kernel\"] = (\"model\", None)\n",
    "layout[\"decoder_block.*ffw_linear.*kernel\"] = (None, \"model\")\n",
    "\n",
    "# The rule means that for any weights that match with token_embedding/embeddings'\n",
    "# will be sharded with model dimensions defined in the mesh (e.g., 2 devices), etc.\n",
    "\n",
    "# Define the model parallel instance - Distribution that shards model variables.\n",
    "model_parallel = keras.distribution.ModelParallel(gpu_mesh, layout, batch_dim_name=\"batch\")\n",
    "\n",
    "# Finally set the distribution globally\n",
    "keras.distribution.set_distribution(model_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d34e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:43:35.760213Z",
     "iopub.status.busy": "2024-08-27T21:43:35.759929Z",
     "iopub.status.idle": "2024-08-27T21:44:40.980926Z",
     "shell.execute_reply": "2024-08-27T21:44:40.979934Z"
    },
    "papermill": {
     "duration": 65.229648,
     "end_time": "2024-08-27T21:44:40.982866",
     "exception": false,
     "start_time": "2024-08-27T21:43:35.753218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import model from Keras\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b042209d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:44:40.999422Z",
     "iopub.status.busy": "2024-08-27T21:44:40.999068Z",
     "iopub.status.idle": "2024-08-27T21:44:41.003842Z",
     "shell.execute_reply": "2024-08-27T21:44:41.003017Z"
    },
    "papermill": {
     "duration": 0.015193,
     "end_time": "2024-08-27T21:44:41.005854",
     "exception": false,
     "start_time": "2024-08-27T21:44:40.990661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Instruction:\\nBelow, the `Original Text` passage has been rewritten/transformed/improved into `Rewritten Text` by the `Gemma 7b-it` LLM with a certain prompt/instruction. Your task is to carefully analyze the differences between the `Original Text` and `Rewritten Text`, and try to infer the specific prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way.\\n\\nOriginal Text:\\n{original_text}\\n\\nRewriten Text:\\n{rewritten_text}\\n\\nResponse:\\n{rewrite_prompt}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f0a57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T21:44:41.022307Z",
     "iopub.status.busy": "2024-08-27T21:44:41.021969Z",
     "iopub.status.idle": "2024-08-27T22:11:41.931054Z",
     "shell.execute_reply": "2024-08-27T22:11:41.929940Z"
    },
    "papermill": {
     "duration": 1620.920506,
     "end_time": "2024-08-27T22:11:41.934117",
     "exception": false,
     "start_time": "2024-08-27T21:44:41.013611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(test)):\n",
    "    row = test.iloc[i]\n",
    "\n",
    "    # Generate Prompt using template\n",
    "    prompt = template.format(\n",
    "        original_text=row.original_text,\n",
    "        rewritten_text=row.rewritten_text,\n",
    "        rewrite_prompt=\"\"\n",
    "    )\n",
    "\n",
    "    # Infer\n",
    "    output = gemma_lm.generate(prompt, max_length=1000)\n",
    "    pred = output.replace(prompt, \"\") # remove the prompt from output\n",
    "    \n",
    "    # Store predictions\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "037fccba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:11:41.951236Z",
     "iopub.status.busy": "2024-08-27T22:11:41.950946Z",
     "iopub.status.idle": "2024-08-27T22:11:41.957061Z",
     "shell.execute_reply": "2024-08-27T22:11:41.956163Z"
    },
    "papermill": {
     "duration": 0.016596,
     "end_time": "2024-08-27T22:11:41.958941",
     "exception": false,
     "start_time": "2024-08-27T22:11:41.942345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prompt or instruction that was likely given to the LLM to rewrite/transform/improve the text in this way is:\\n\\n\"The LLM was likely given the prompt or instruction to rewrite/transform/improve the text in this way to highlight the importance of equality and inclusion in our society, and to emphasize the need for empathy, understanding, and respect for all individuals.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d92fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:11:41.975588Z",
     "iopub.status.busy": "2024-08-27T22:11:41.975291Z",
     "iopub.status.idle": "2024-08-27T22:11:41.990690Z",
     "shell.execute_reply": "2024-08-27T22:11:41.989872Z"
    },
    "papermill": {
     "duration": 0.026128,
     "end_time": "2024-08-27T22:11:41.992626",
     "exception": false,
     "start_time": "2024-08-27T22:11:41.966498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The prompt for this LLM was to rewrite the ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear grandchild,\\n\\nI am so sorry to hear abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instruction:\\nBelow, the `Original Text` passa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Dear [Company Name] Employees,\\n\\nThank you fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  pred\n",
       "0    The prompt or instruction that was likely give...\n",
       "1    The prompt for this LLM was to rewrite the ori...\n",
       "2    Dear grandchild,\\n\\nI am so sorry to hear abou...\n",
       "3    The prompt or instruction that was likely give...\n",
       "4    Instruction:\\nBelow, the `Original Text` passa...\n",
       "..                                                 ...\n",
       "190  The prompt or instruction that was likely give...\n",
       "191  The prompt or instruction that was likely give...\n",
       "192  Dear [Company Name] Employees,\\n\\nThank you fo...\n",
       "193  The prompt or instruction that was likely give...\n",
       "194  The prompt or instruction that was likely give...\n",
       "\n",
       "[195 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'pred': preds})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0082152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:11:42.009922Z",
     "iopub.status.busy": "2024-08-27T22:11:42.009262Z",
     "iopub.status.idle": "2024-08-27T22:11:42.024539Z",
     "shell.execute_reply": "2024-08-27T22:11:42.023560Z"
    },
    "papermill": {
     "duration": 0.025986,
     "end_time": "2024-08-27T22:11:42.026456",
     "exception": false,
     "start_time": "2024-08-27T22:11:42.000470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35244642</td>\n",
       "      <td>Roy Moore's administrative order defies a US S...</td>\n",
       "      <td>Frame this as a message from the future.</td>\n",
       "      <td>**Message from the Future:**\\n\\n\"Greetings fro...</td>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UUsPjrHjwH</td>\n",
       "      <td>Her cool, magic filled hands caressed his stro...</td>\n",
       "      <td>Rewrite the story as a romcom / love story</td>\n",
       "      <td>In the quaint halls of the Pigfreckles School ...</td>\n",
       "      <td>The prompt for this LLM was to rewrite the ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29540559</td>\n",
       "      <td>Jill Hutchinson-Grigg, 54, accidentally hit a ...</td>\n",
       "      <td>Convert the text into a grandparent's advice t...</td>\n",
       "      <td>My dear grandchild,\\n\\nI know you're going thr...</td>\n",
       "      <td>Dear grandchild,\\n\\nI am so sorry to hear abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40666889</td>\n",
       "      <td>Torrential downpours affected properties in Bl...</td>\n",
       "      <td>Describe this as an Olympic sport commentary.</td>\n",
       "      <td>\"Good evening, ladies and gentlefolk, and welc...</td>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VMtuViHepp</td>\n",
       "      <td>`` You people have to be kidding me. Magic doe...</td>\n",
       "      <td>Rewrite the story as an action movie with a gr...</td>\n",
       "      <td>\"The roar of the alien spacecraft echoed throu...</td>\n",
       "      <td>Instruction:\\nBelow, the `Original Text` passa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>34841098</td>\n",
       "      <td>The 21-year-old local man was in the front sea...</td>\n",
       "      <td>Adapt it as an ancient Egyptian hieroglyphic m...</td>\n",
       "      <td>**Hieroglyphic Message:**\\n\\nThe serpent's ton...</td>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>36425660</td>\n",
       "      <td>The 26-year-old will join the Shrimps on a two...</td>\n",
       "      <td>Write the text as if it were a vintage travel ...</td>\n",
       "      <td>**Journey along with the Shrimps to Paradise!*...</td>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>37677698</td>\n",
       "      <td>Ben Gwynne captured the sight on the moors abo...</td>\n",
       "      <td>Adapt this into a company newsletter article.</td>\n",
       "      <td>**Subject: Rare Lunar Rainbow Spotted in North...</td>\n",
       "      <td>Dear [Company Name] Employees,\\n\\nThank you fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>40056423</td>\n",
       "      <td>A high of 25.8C was recorded at Magilligan in ...</td>\n",
       "      <td>Turn this into a story about a molecule that d...</td>\n",
       "      <td>In the heart of the tiniest star dust, where c...</td>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>38980248</td>\n",
       "      <td>Mr Harris has pleaded not guilty to the new ch...</td>\n",
       "      <td>Rewrite the message as a chess master's strate...</td>\n",
       "      <td>In order to win games, one must employ a multi...</td>\n",
       "      <td>The prompt or instruction that was likely give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      original_text  \\\n",
       "0      35244642  Roy Moore's administrative order defies a US S...   \n",
       "1    UUsPjrHjwH  Her cool, magic filled hands caressed his stro...   \n",
       "2      29540559  Jill Hutchinson-Grigg, 54, accidentally hit a ...   \n",
       "3      40666889  Torrential downpours affected properties in Bl...   \n",
       "4    VMtuViHepp  `` You people have to be kidding me. Magic doe...   \n",
       "..          ...                                                ...   \n",
       "190    34841098  The 21-year-old local man was in the front sea...   \n",
       "191    36425660  The 26-year-old will join the Shrimps on a two...   \n",
       "192    37677698  Ben Gwynne captured the sight on the moors abo...   \n",
       "193    40056423  A high of 25.8C was recorded at Magilligan in ...   \n",
       "194    38980248  Mr Harris has pleaded not guilty to the new ch...   \n",
       "\n",
       "                                        rewrite_prompt  \\\n",
       "0             Frame this as a message from the future.   \n",
       "1           Rewrite the story as a romcom / love story   \n",
       "2    Convert the text into a grandparent's advice t...   \n",
       "3        Describe this as an Olympic sport commentary.   \n",
       "4    Rewrite the story as an action movie with a gr...   \n",
       "..                                                 ...   \n",
       "190  Adapt it as an ancient Egyptian hieroglyphic m...   \n",
       "191  Write the text as if it were a vintage travel ...   \n",
       "192      Adapt this into a company newsletter article.   \n",
       "193  Turn this into a story about a molecule that d...   \n",
       "194  Rewrite the message as a chess master's strate...   \n",
       "\n",
       "                                        rewritten_text  \\\n",
       "0    **Message from the Future:**\\n\\n\"Greetings fro...   \n",
       "1    In the quaint halls of the Pigfreckles School ...   \n",
       "2    My dear grandchild,\\n\\nI know you're going thr...   \n",
       "3    \"Good evening, ladies and gentlefolk, and welc...   \n",
       "4    \"The roar of the alien spacecraft echoed throu...   \n",
       "..                                                 ...   \n",
       "190  **Hieroglyphic Message:**\\n\\nThe serpent's ton...   \n",
       "191  **Journey along with the Shrimps to Paradise!*...   \n",
       "192  **Subject: Rare Lunar Rainbow Spotted in North...   \n",
       "193  In the heart of the tiniest star dust, where c...   \n",
       "194  In order to win games, one must employ a multi...   \n",
       "\n",
       "                                                  pred  \n",
       "0    The prompt or instruction that was likely give...  \n",
       "1    The prompt for this LLM was to rewrite the ori...  \n",
       "2    Dear grandchild,\\n\\nI am so sorry to hear abou...  \n",
       "3    The prompt or instruction that was likely give...  \n",
       "4    Instruction:\\nBelow, the `Original Text` passa...  \n",
       "..                                                 ...  \n",
       "190  The prompt or instruction that was likely give...  \n",
       "191  The prompt or instruction that was likely give...  \n",
       "192  Dear [Company Name] Employees,\\n\\nThank you fo...  \n",
       "193  The prompt or instruction that was likely give...  \n",
       "194  The prompt or instruction that was likely give...  \n",
       "\n",
       "[195 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([test, df], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c7a3757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:11:42.044068Z",
     "iopub.status.busy": "2024-08-27T22:11:42.043807Z",
     "iopub.status.idle": "2024-08-27T22:11:55.910472Z",
     "shell.execute_reply": "2024-08-27T22:11:55.909343Z"
    },
    "papermill": {
     "duration": 13.877858,
     "end_time": "2024-08-27T22:11:55.912829",
     "exception": false,
     "start_time": "2024-08-27T22:11:42.034971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uq /kaggle/input/sentence-transformers-2-4-0/sentence_transformers-2.4.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae08c8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:11:55.931278Z",
     "iopub.status.busy": "2024-08-27T22:11:55.930955Z",
     "iopub.status.idle": "2024-08-27T22:11:57.821033Z",
     "shell.execute_reply": "2024-08-27T22:11:57.820036Z"
    },
    "papermill": {
     "duration": 1.902017,
     "end_time": "2024-08-27T22:11:57.823389",
     "exception": false,
     "start_time": "2024-08-27T22:11:55.921372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1399a26a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:11:57.843967Z",
     "iopub.status.busy": "2024-08-27T22:11:57.842484Z",
     "iopub.status.idle": "2024-08-27T22:12:09.520974Z",
     "shell.execute_reply": "2024-08-27T22:12:09.519837Z"
    },
    "papermill": {
     "duration": 11.689756,
     "end_time": "2024-08-27T22:12:09.522942",
     "exception": false,
     "start_time": "2024-08-27T22:11:57.833186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               Frame this as a message from the future.\n",
      "1             Rewrite the story as a romcom / love story\n",
      "2      Convert the text into a grandparent's advice t...\n",
      "3          Describe this as an Olympic sport commentary.\n",
      "4      Rewrite the story as an action movie with a gr...\n",
      "                             ...                        \n",
      "190    Adapt it as an ancient Egyptian hieroglyphic m...\n",
      "191    Write the text as if it were a vintage travel ...\n",
      "192        Adapt this into a company newsletter article.\n",
      "193    Turn this into a story about a molecule that d...\n",
      "194    Rewrite the message as a chess master's strate...\n",
      "Name: rewrite_prompt, Length: 195, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:03<00:00, 59.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [[-0.018073421, -0.030402295, 0.003190786, 0.0...\n",
      "1      [[-0.027386943, 0.014050057, 0.040082913, 0.03...\n",
      "2      [[0.002568368, -0.0461105, 0.04272737, 0.06538...\n",
      "3      [[-0.02944915, -0.010447316, -0.00022800422, 0...\n",
      "4      [[-0.034108885, -0.0333137, 0.035215627, 0.005...\n",
      "                             ...                        \n",
      "190    [[-0.036863532, -0.023867188, 0.02022138, 0.04...\n",
      "191    [[-0.02942239, -0.016223524, 0.0029148825, 0.0...\n",
      "192    [[-0.00045411813, -0.010155952, -0.011178258, ...\n",
      "193    [[-0.019369064, -0.02324807, 0.029670076, 0.05...\n",
      "194    [[-0.04206502, -0.033440344, 0.030094832, 0.06...\n",
      "Name: actual_embeddings, Length: 195, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:03<00:00, 51.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 0.4877890646457672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def CVScore(test):\n",
    "    \n",
    "    scs = lambda row: abs((cosine_similarity(row[\"actual_embeddings\"], row[\"pred_embeddings\"])) ** 3)\n",
    "    \n",
    "    model = SentenceTransformer('/kaggle/input/sentence-t5-base-hf/sentence-t5-base')\n",
    "    \n",
    "    print(test[\"rewrite_prompt\"])\n",
    "\n",
    "    test[\"actual_embeddings\"] = test[\"rewrite_prompt\"].progress_apply(lambda x: model.encode(x, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1))\n",
    "    print(test[\"actual_embeddings\"])\n",
    "    test[\"pred_embeddings\"] = test[\"pred\"].progress_apply(lambda x: model.encode(x, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1))\n",
    "    \n",
    "    test[\"score\"] = test.apply(scs, axis=1)\n",
    "    \n",
    "    return np.mean(test['score'])[0][0]\n",
    "    \n",
    "print(f\"CV Score: {CVScore(test)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4516155,
     "sourceId": 7729151,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4516250,
     "sourceId": 7729275,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4649503,
     "sourceId": 7913629,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4762456,
     "sourceId": 8071209,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1737.98403,
   "end_time": "2024-08-27T22:12:12.987115",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-27T21:43:15.003085",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
