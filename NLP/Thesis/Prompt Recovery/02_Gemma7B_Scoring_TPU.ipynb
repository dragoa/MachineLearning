{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c494d4e",
   "metadata": {
    "papermill": {
     "duration": 0.006792,
     "end_time": "2024-08-28T09:24:13.179378",
     "exception": false,
     "start_time": "2024-08-28T09:24:13.172586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup Gemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4100f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:24:13.194335Z",
     "iopub.status.busy": "2024-08-28T09:24:13.194066Z",
     "iopub.status.idle": "2024-08-28T09:25:57.100089Z",
     "shell.execute_reply": "2024-08-28T09:25:57.099280Z"
    },
    "papermill": {
     "duration": 103.915685,
     "end_time": "2024-08-28T09:25:57.102629",
     "exception": false,
     "start_time": "2024-08-28T09:24:13.186944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-nlp 0.8.1 requires keras-core, which is not installed.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tensorflow-cpu\n",
    "!pip install -q -U keras-nlp tensorflow-hub\n",
    "!pip install -q -U keras>=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e3f23",
   "metadata": {
    "papermill": {
     "duration": 0.00635,
     "end_time": "2024-08-28T09:25:57.115374",
     "exception": false,
     "start_time": "2024-08-28T09:25:57.109024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Choose a Backend:\n",
    "Keras, a user-friendly high-level deep learning API, is crafted for simplicity and seamless usage across multiple frameworks. With Keras 3, you have the flexibility to execute workflows on one of three backends: TensorFlow, JAX, or PyTorch. In this tutorial, we'll configure the backend to utilize JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cfa620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:25:57.129553Z",
     "iopub.status.busy": "2024-08-28T09:25:57.129283Z",
     "iopub.status.idle": "2024-08-28T09:26:05.837612Z",
     "shell.execute_reply": "2024-08-28T09:26:05.836845Z"
    },
    "papermill": {
     "duration": 8.718041,
     "end_time": "2024-08-28T09:26:05.839577",
     "exception": false,
     "start_time": "2024-08-28T09:25:57.121536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1724837162.024958      14 common_lib.cc:778] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: === \n",
      "learning/45eac/tfrc/runtime/common_lib.cc:467\n",
      "E0828 09:26:02.060062363     121 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-08-28T09:26:02.060045646+00:00\", grpc_status:2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
       " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
       " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
       " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
       " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a997c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:05.855837Z",
     "iopub.status.busy": "2024-08-28T09:26:05.855439Z",
     "iopub.status.idle": "2024-08-28T09:26:06.585437Z",
     "shell.execute_reply": "2024-08-28T09:26:06.584651Z"
    },
    "papermill": {
     "duration": 0.740208,
     "end_time": "2024-08-28T09:26:06.587345",
     "exception": false,
     "start_time": "2024-08-28T09:26:05.847137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14/3747930928.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Datasets we use\n",
    "os.environ[\"DATASET1\"] = \"/kaggle/input/gemma-rewrite-nbroad/nbroad-v2.csv\"\n",
    "os.environ[\"DATASET2\"] = \"/kaggle/input/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv\"\n",
    "# The Keras 3 distribution API is only implemented for the JAX backend for now\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation\n",
    "# overhead\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c80c3f",
   "metadata": {
    "papermill": {
     "duration": 0.006117,
     "end_time": "2024-08-28T09:26:06.600328",
     "exception": false,
     "start_time": "2024-08-28T09:26:06.594211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5bcf2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:06.614886Z",
     "iopub.status.busy": "2024-08-28T09:26:06.614108Z",
     "iopub.status.idle": "2024-08-28T09:26:13.955138Z",
     "shell.execute_reply": "2024-08-28T09:26:13.953956Z"
    },
    "papermill": {
     "duration": 7.3503,
     "end_time": "2024-08-28T09:26:13.957070",
     "exception": false,
     "start_time": "2024-08-28T09:26:06.606770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e7c1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:13.972575Z",
     "iopub.status.busy": "2024-08-28T09:26:13.972068Z",
     "iopub.status.idle": "2024-08-28T09:26:13.979580Z",
     "shell.execute_reply": "2024-08-28T09:26:13.978744Z"
    },
    "papermill": {
     "duration": 0.017048,
     "end_time": "2024-08-28T09:26:13.981256",
     "exception": false,
     "start_time": "2024-08-28T09:26:13.964208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tpu:0', 'tpu:1', 'tpu:2', 'tpu:3', 'tpu:4', 'tpu:5', 'tpu:6', 'tpu:7']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import os\n",
    "\n",
    "# The Keras 3 distribution API is only implemented for the JAX backend for now\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation overhead\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\"\n",
    "\n",
    "print(jax.devices())\n",
    "\n",
    "import keras\n",
    "keras.distribution.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "310091fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:13.995644Z",
     "iopub.status.busy": "2024-08-28T09:26:13.995398Z",
     "iopub.status.idle": "2024-08-28T09:26:14.001362Z",
     "shell.execute_reply": "2024-08-28T09:26:14.000669Z"
    },
    "papermill": {
     "duration": 0.01521,
     "end_time": "2024-08-28T09:26:14.003036",
     "exception": false,
     "start_time": "2024-08-28T09:26:13.987826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeviceMesh shape=(1, 8), axis_names=['batch', 'model']>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from tensorflow import data as tf_data  # For dataset input.\n",
    "\n",
    "num_gpu=len(keras.distribution.list_devices())\n",
    "# there are 2 cudas in TPU T4x2 - VMv3-8 has 8\n",
    "gpu_mesh = keras.distribution.DeviceMesh(\n",
    "    shape=(1,num_gpu),\n",
    "    axis_names=[\"batch\", \"model\"], \n",
    "    devices=keras.distribution.list_devices()\n",
    ")\n",
    "gpu_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0dfea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:14.051454Z",
     "iopub.status.busy": "2024-08-28T09:26:14.051203Z",
     "iopub.status.idle": "2024-08-28T09:26:14.056312Z",
     "shell.execute_reply": "2024-08-28T09:26:14.055608Z"
    },
    "papermill": {
     "duration": 0.048217,
     "end_time": "2024-08-28T09:26:14.057825",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.009608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a LayoutMap instance\n",
    "layout = keras.distribution.LayoutMap(device_mesh=gpu_mesh)\n",
    "\n",
    "# Regex to match against the query, key and value matrices in attention layers\n",
    "layout[\"decoder_block.*attention.*(query|key|value)/kernel\"] = (\"model\", None, None)\n",
    "layout[\"decoder_block.*attention_output/kernel\"] = (\"model\", None, None)\n",
    "layout[\"decoder_block.*ffw_gating.*/kernel\"] = (None, \"model\")\n",
    "layout[\"decoder_block.*ffw_linear/kernel\"] = (\"model\", None)\n",
    "\n",
    "# The rule means that for any weights that match with token_embedding/embeddings'\n",
    "# will be sharded with model dimensions defined in the mesh (e.g., 2 devices), etc.\n",
    "\n",
    "# Define the model parallel instance - Distribution that shards model variables.\n",
    "model_parallel = keras.distribution.ModelParallel(layout_map=layout, batch_dim_name=\"batch\")\n",
    "\n",
    "# Finally set the distribution globally\n",
    "keras.distribution.set_distribution(model_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a821874",
   "metadata": {
    "papermill": {
     "duration": 0.006383,
     "end_time": "2024-08-28T09:26:14.070831",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.064448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48578c",
   "metadata": {
    "papermill": {
     "duration": 0.006478,
     "end_time": "2024-08-28T09:26:14.083948",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.077470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "No training data is provided in this competition, but we know what is the structure of it.\n",
    "* *original_text*: Text in input to the LLM that needs to be transformed.\n",
    "* *rewrite_prompt*: Prompt/Instruction that was used in the Gemma to transform *original_text*. This is also the target for this competition.\n",
    "* rewritten_text: Output text that was generated by the Gemma model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ddd126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:14.098746Z",
     "iopub.status.busy": "2024-08-28T09:26:14.098458Z",
     "iopub.status.idle": "2024-08-28T09:26:14.119309Z",
     "shell.execute_reply": "2024-08-28T09:26:14.118475Z"
    },
    "papermill": {
     "duration": 0.030472,
     "end_time": "2024-08-28T09:26:14.121004",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.090532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.</td>\n",
       "      <td>Convert this into a sea shanty: \"\"\"The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\"\"\"</td>\n",
       "      <td>Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0  -1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                original_text  \\\n",
       "0  The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     rewrite_prompt  \\\n",
       "0  Convert this into a sea shanty: \"\"\"The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\"\"\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                 rewritten_text  \n",
       "0  Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 512)\n",
    "df = pd.read_csv('/kaggle/input/llm-prompt-recovery/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db809f",
   "metadata": {
    "papermill": {
     "duration": 0.006632,
     "end_time": "2024-08-28T09:26:14.134438",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.127806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We use external data that uses Gemma for transforming text using a prompt. Let's take a look at this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a8e2a",
   "metadata": {
    "papermill": {
     "duration": 0.006894,
     "end_time": "2024-08-28T09:26:14.147907",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.141013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the template that our model expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2fe0f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:14.165095Z",
     "iopub.status.busy": "2024-08-28T09:26:14.164781Z",
     "iopub.status.idle": "2024-08-28T09:26:14.169623Z",
     "shell.execute_reply": "2024-08-28T09:26:14.168832Z"
    },
    "papermill": {
     "duration": 0.015105,
     "end_time": "2024-08-28T09:26:14.171355",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.156250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = (\n",
    "    \"<start_of_turn>user\\nGenerate a rewrite_prompt that effectively transforms the given original_text into the provided rewritten_text.\"\n",
    "    \"Capture the essence and context of the content while improving the language, coherence, and expressiveness.\"\n",
    "    \"Pay attention to detail, clarity, and overall quality in your generated rewrite_prompt.\"\n",
    "    \"Here is an example sample: original text-\" + df.loc[0, 'original_text'] +\n",
    "    \"rewritten_text-\" + df.loc[0, 'rewritten_text'] +\n",
    "    \"and this is the right rewrite_prompt-\" + df.loc[0, 'rewrite_prompt'] +\n",
    "    \"Now, You will output in text the most suitable rewrite_prompt. For the given original_text- {original_text}\" +\n",
    "    \"and rewritten_text- {rewritten_text}\" +\n",
    "    \"<end_of_turn>\\n<start_of_turn>model\\nrewrite_prompt- {rewrite_prompt}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839014ac",
   "metadata": {
    "papermill": {
     "duration": 0.006717,
     "end_time": "2024-08-28T09:26:14.185034",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.178317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e631f24",
   "metadata": {
    "papermill": {
     "duration": 0.006773,
     "end_time": "2024-08-28T09:26:14.198253",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.191480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's load the model by using keras_nlp library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8556063d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:26:14.213326Z",
     "iopub.status.busy": "2024-08-28T09:26:14.212661Z",
     "iopub.status.idle": "2024-08-28T09:29:04.900428Z",
     "shell.execute_reply": "2024-08-28T09:29:04.899414Z"
    },
    "papermill": {
     "duration": 170.697333,
     "end_time": "2024-08-28T09:29:04.902392",
     "exception": false,
     "start_time": "2024-08-28T09:26:14.205059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors.index.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'task.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors.index.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors.index.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_7b_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,537,680,896</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">786,432,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)        │   \u001b[38;5;34m8,537,680,896\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m786,432,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,537,680,896</span> (31.81 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,537,680,896\u001b[0m (31.81 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,537,680,896</span> (31.81 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,537,680,896\u001b[0m (31.81 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import model from Keras\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_7b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f450691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:04.923041Z",
     "iopub.status.busy": "2024-08-28T09:29:04.922742Z",
     "iopub.status.idle": "2024-08-28T09:29:04.926480Z",
     "shell.execute_reply": "2024-08-28T09:29:04.925704Z"
    },
    "papermill": {
     "duration": 0.016099,
     "end_time": "2024-08-28T09:29:04.928067",
     "exception": false,
     "start_time": "2024-08-28T09:29:04.911968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "MODEL_LORA_WT_PATH = \"/kaggle/input/gemma-7b-finetuned-model-weights/model.weights.lora.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c03ea7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:04.947696Z",
     "iopub.status.busy": "2024-08-28T09:29:04.947442Z",
     "iopub.status.idle": "2024-08-28T09:29:05.656381Z",
     "shell.execute_reply": "2024-08-28T09:29:05.655171Z"
    },
    "papermill": {
     "duration": 0.721539,
     "end_time": "2024-08-28T09:29:05.658886",
     "exception": false,
     "start_time": "2024-08-28T09:29:04.937347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lora rank enablement... same as before\n",
    "gemma_lm.backbone.enable_lora(rank=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63307a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:05.678840Z",
     "iopub.status.busy": "2024-08-28T09:29:05.678453Z",
     "iopub.status.idle": "2024-08-28T09:29:06.670294Z",
     "shell.execute_reply": "2024-08-28T09:29:06.669167Z"
    },
    "papermill": {
     "duration": 1.00468,
     "end_time": "2024-08-28T09:29:06.672694",
     "exception": false,
     "start_time": "2024-08-28T09:29:05.668014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limit the input sequence length to 512 (to control memory usage)... same as before\n",
    "gemma_lm.preprocessor.sequence_length = 512\n",
    "\n",
    "# Load only the lora weights in...\n",
    "gemma_lm.backbone.load_lora_weights(MODEL_LORA_WT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768e2c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:06.692644Z",
     "iopub.status.busy": "2024-08-28T09:29:06.692365Z",
     "iopub.status.idle": "2024-08-28T09:29:06.695896Z",
     "shell.execute_reply": "2024-08-28T09:29:06.695140Z"
    },
    "papermill": {
     "duration": 0.015237,
     "end_time": "2024-08-28T09:29:06.697468",
     "exception": false,
     "start_time": "2024-08-28T09:29:06.682231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use mixed precision to speed up all training\n",
    "#keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d5a83",
   "metadata": {
    "papermill": {
     "duration": 0.00906,
     "end_time": "2024-08-28T09:29:06.715172",
     "exception": false,
     "start_time": "2024-08-28T09:29:06.706112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference before finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87824a0",
   "metadata": {
    "papermill": {
     "duration": 0.008554,
     "end_time": "2024-08-28T09:29:06.732302",
     "exception": false,
     "start_time": "2024-08-28T09:29:06.723748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's attempt to pose a question to the Gemma model before fine-tuning it with our dataset, to observe how Gemma responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0803e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:06.750672Z",
     "iopub.status.busy": "2024-08-28T09:29:06.750376Z",
     "iopub.status.idle": "2024-08-28T09:29:32.299033Z",
     "shell.execute_reply": "2024-08-28T09:29:32.297841Z"
    },
    "papermill": {
     "duration": 25.559953,
     "end_time": "2024-08-28T09:29:32.300858",
     "exception": false,
     "start_time": "2024-08-28T09:29:06.740905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start_of_turn>user\\nGenerate a rewrite_prompt that effectively transforms the given original_text into the provided rewritten_text.Capture the essence and context of the content while improving the language, coherence, and expressiveness.Pay attention to detail, clarity, and overall quality in your generated rewrite_prompt.Here is an example sample: original text-The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.rewritten_text-Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they\\'ve been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we\\'ll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to beand this is the right rewrite_prompt-Convert this into a sea shanty: \"\"\"The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\"\"\"Now, You will output in text the most suitable rewrite_prompt. For the given original_text- The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.and rewritten_text- Here is your shanty: (Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they\\'ve been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we\\'ll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be<end_of_turn>\\n<start_of_turn>model\\nrewrite_prompt- Convert this into a sea shanty.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take one sample\n",
    "row = df.iloc[0]\n",
    "\n",
    "# Generate Prompt using template\n",
    "prompt = template.format(\n",
    "    original_text=row.original_text,\n",
    "    rewritten_text=row.rewritten_text,\n",
    "    rewrite_prompt=\"\",\n",
    ")\n",
    "\n",
    "# Infer\n",
    "output = gemma_lm.generate(prompt, max_length=2000)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391953e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:32.321108Z",
     "iopub.status.busy": "2024-08-28T09:29:32.320722Z",
     "iopub.status.idle": "2024-08-28T09:29:32.325763Z",
     "shell.execute_reply": "2024-08-28T09:29:32.324920Z"
    },
    "papermill": {
     "duration": 0.016759,
     "end_time": "2024-08-28T09:29:32.327258",
     "exception": false,
     "start_time": "2024-08-28T09:29:32.310499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrite Prompt:\n",
      " rewrite_prompt- Convert this into a sea shanty.\n"
     ]
    }
   ],
   "source": [
    "# We see that the model hallucinates!\n",
    "print(\"Rewrite Prompt:\\n\", output.split(\"\\n<start_of_turn>model\")[1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f5d2e",
   "metadata": {
    "papermill": {
     "duration": 0.008669,
     "end_time": "2024-08-28T09:29:32.344780",
     "exception": false,
     "start_time": "2024-08-28T09:29:32.336111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d9798",
   "metadata": {
    "papermill": {
     "duration": 0.0085,
     "end_time": "2024-08-28T09:29:32.361987",
     "exception": false,
     "start_time": "2024-08-28T09:29:32.353487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we take a new dataset and we try to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eacc13d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:32.380656Z",
     "iopub.status.busy": "2024-08-28T09:29:32.380391Z",
     "iopub.status.idle": "2024-08-28T09:29:36.062445Z",
     "shell.execute_reply": "2024-08-28T09:29:36.061019Z"
    },
    "papermill": {
     "duration": 3.694501,
     "end_time": "2024-08-28T09:29:36.064943",
     "exception": false,
     "start_time": "2024-08-28T09:29:32.370442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq /kaggle/input/sentence-transformers-2-4-0/sentence_transformers-2.4.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5ab0e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:36.085538Z",
     "iopub.status.busy": "2024-08-28T09:29:36.085196Z",
     "iopub.status.idle": "2024-08-28T09:29:58.911100Z",
     "shell.execute_reply": "2024-08-28T09:29:58.910011Z"
    },
    "papermill": {
     "duration": 22.838949,
     "end_time": "2024-08-28T09:29:58.913565",
     "exception": false,
     "start_time": "2024-08-28T09:29:36.074616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a7a34ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:58.934243Z",
     "iopub.status.busy": "2024-08-28T09:29:58.933559Z",
     "iopub.status.idle": "2024-08-28T09:29:59.027527Z",
     "shell.execute_reply": "2024-08-28T09:29:59.026501Z"
    },
    "papermill": {
     "duration": 0.106507,
     "end_time": "2024-08-28T09:29:59.029442",
     "exception": false,
     "start_time": "2024-08-28T09:29:58.922935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df =  pd.read_csv(\"/kaggle/input/llm-prompt-recovery-ground-truth-1/test (1).csv\")\n",
    "test_df = test_df.head(195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba6fd5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:29:59.048909Z",
     "iopub.status.busy": "2024-08-28T09:29:59.048600Z",
     "iopub.status.idle": "2024-08-28T09:31:24.657112Z",
     "shell.execute_reply": "2024-08-28T09:31:24.656163Z"
    },
    "papermill": {
     "duration": 85.621204,
     "end_time": "2024-08-28T09:31:24.659652",
     "exception": false,
     "start_time": "2024-08-28T09:29:59.038448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(test_df)):\n",
    "    row = test_df.iloc[i]\n",
    "\n",
    "    # Generate Prompt using template\n",
    "    prompt = template.format(\n",
    "        original_text=row.original_text,\n",
    "        rewritten_text=row.rewritten_text,\n",
    "        rewrite_prompt=\"\"\n",
    "    )\n",
    "\n",
    "    # Infer\n",
    "    output = gemma_lm.generate(prompt, max_length=2000)\n",
    "    pred = output.replace(prompt, \"\") # remove the prompt from output\n",
    "    \n",
    "    # Store predictions\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df34f482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:31:24.679731Z",
     "iopub.status.busy": "2024-08-28T09:31:24.679474Z",
     "iopub.status.idle": "2024-08-28T09:31:24.684456Z",
     "shell.execute_reply": "2024-08-28T09:31:24.683829Z"
    },
    "papermill": {
     "duration": 0.016867,
     "end_time": "2024-08-28T09:31:24.686005",
     "exception": false,
     "start_time": "2024-08-28T09:31:24.669138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transform this into a gourmet food festival brochure.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97668e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:31:24.705013Z",
     "iopub.status.busy": "2024-08-28T09:31:24.704764Z",
     "iopub.status.idle": "2024-08-28T09:31:24.708325Z",
     "shell.execute_reply": "2024-08-28T09:31:24.707728Z"
    },
    "papermill": {
     "duration": 0.015174,
     "end_time": "2024-08-28T09:31:24.710128",
     "exception": false,
     "start_time": "2024-08-28T09:31:24.694954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, val in enumerate(preds):\n",
    "    # Check if the current element contains \"<start_of_turn>\"\n",
    "    if \"<start_of_turn>\" in val:\n",
    "        # Replace the element at index i with the sentence \"Improve this text.\"\n",
    "        preds[i] = \"Improve this text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcf1f2b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:31:24.729497Z",
     "iopub.status.busy": "2024-08-28T09:31:24.729272Z",
     "iopub.status.idle": "2024-08-28T09:31:24.739286Z",
     "shell.execute_reply": "2024-08-28T09:31:24.738655Z"
    },
    "papermill": {
     "duration": 0.021634,
     "end_time": "2024-08-28T09:31:24.740910",
     "exception": false,
     "start_time": "2024-08-28T09:31:24.719276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40837062</td>\n",
       "      <td>South Wales Police officers had been pursuing a red Ford Focus around the Cardiff area at about 18:00 BST on Saturday. A stinger was also used.\\nMinutes later, the car collided with a Land Rover Freelander on the eastbound side between junctions 30 and 32.\\nThe Independent Police Complaints Commission is probing the incident.\\nPolice said the Land Rover's driver was cut free but did not suffer serious injuries.\\nThe Ford's Gloucester-based driver died.\\nAn IPCC spokesman said: \"We were notified by South...</td>\n",
       "      <td>Make the text into a gourmet food festival brochure</td>\n",
       "      <td>## Gourmet Food Festival Brochure\\n\\n**Indulge Your Senses at the Exquisite Gourmet Food Festival**\\n\\n**A Culinary Celebration of the finest flavors**\\n\\nJoin us at the South Wales Food Festival, a vibrant celebration of the very best in gourmet cuisine. Immerse yourself in a symphony of aromas, textures, and tastes that will tantalize your senses and leave you wanting more.\\n\\n**The festival features:**\\n\\n* **Delectable food stalls:** Sample an array of mouth-watering dishes from around the world, in...</td>\n",
       "      <td>Transform this into a gourmet food festival brochure.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  40837062   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     original_text  \\\n",
       "0  South Wales Police officers had been pursuing a red Ford Focus around the Cardiff area at about 18:00 BST on Saturday. A stinger was also used.\\nMinutes later, the car collided with a Land Rover Freelander on the eastbound side between junctions 30 and 32.\\nThe Independent Police Complaints Commission is probing the incident.\\nPolice said the Land Rover's driver was cut free but did not suffer serious injuries.\\nThe Ford's Gloucester-based driver died.\\nAn IPCC spokesman said: \"We were notified by South...   \n",
       "\n",
       "                                        rewrite_prompt  \\\n",
       "0  Make the text into a gourmet food festival brochure   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    rewritten_text  \\\n",
       "0  ## Gourmet Food Festival Brochure\\n\\n**Indulge Your Senses at the Exquisite Gourmet Food Festival**\\n\\n**A Culinary Celebration of the finest flavors**\\n\\nJoin us at the South Wales Food Festival, a vibrant celebration of the very best in gourmet cuisine. Immerse yourself in a symphony of aromas, textures, and tastes that will tantalize your senses and leave you wanting more.\\n\\n**The festival features:**\\n\\n* **Delectable food stalls:** Sample an array of mouth-watering dishes from around the world, in...   \n",
       "\n",
       "                                                    pred  \n",
       "0  Transform this into a gourmet food festival brochure.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'pred': preds})\n",
    "test_df = pd.concat([test_df, df], axis=1)\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57d192dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:31:24.760422Z",
     "iopub.status.busy": "2024-08-28T09:31:24.760197Z",
     "iopub.status.idle": "2024-08-28T09:31:39.330615Z",
     "shell.execute_reply": "2024-08-28T09:31:39.329814Z"
    },
    "papermill": {
     "duration": 14.582188,
     "end_time": "2024-08-28T09:31:39.332354",
     "exception": false,
     "start_time": "2024-08-28T09:31:24.750166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 5/195 [00:00<00:04, 43.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 10/195 [00:00<00:04, 37.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 15/195 [00:00<00:04, 40.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 20/195 [00:00<00:04, 40.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 25/195 [00:00<00:04, 41.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 30/195 [00:00<00:04, 40.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 35/195 [00:00<00:04, 39.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 40/195 [00:00<00:03, 40.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 45/195 [00:01<00:03, 40.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 50/195 [00:01<00:03, 40.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 55/195 [00:01<00:03, 40.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 60/195 [00:01<00:03, 40.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 65/195 [00:01<00:03, 41.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 70/195 [00:01<00:03, 41.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 75/195 [00:01<00:02, 42.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 80/195 [00:01<00:02, 42.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 85/195 [00:02<00:02, 40.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 90/195 [00:02<00:02, 39.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 94/195 [00:02<00:02, 39.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 98/195 [00:02<00:02, 39.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 103/195 [00:02<00:02, 40.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 108/195 [00:02<00:02, 41.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 113/195 [00:02<00:01, 42.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 118/195 [00:02<00:01, 44.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 123/195 [00:02<00:01, 44.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 128/195 [00:03<00:01, 43.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 133/195 [00:03<00:01, 42.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 138/195 [00:03<00:01, 42.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 143/195 [00:03<00:01, 43.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 148/195 [00:03<00:01, 43.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 153/195 [00:03<00:00, 44.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 158/195 [00:03<00:00, 45.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▎ | 163/195 [00:03<00:00, 44.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 168/195 [00:04<00:00, 44.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 173/195 [00:04<00:00, 44.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 178/195 [00:04<00:00, 44.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 183/195 [00:04<00:00, 44.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 188/195 [00:04<00:00, 45.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 193/195 [00:04<00:00, 45.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 195/195 [00:04<00:00, 42.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 6/195 [00:00<00:03, 55.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 12/195 [00:00<00:04, 45.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 17/195 [00:00<00:03, 44.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 22/195 [00:00<00:03, 44.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 27/195 [00:00<00:03, 43.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 32/195 [00:00<00:03, 43.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 37/195 [00:00<00:03, 44.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 42/195 [00:00<00:03, 43.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 47/195 [00:01<00:03, 43.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 52/195 [00:01<00:03, 42.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 57/195 [00:01<00:03, 43.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 62/195 [00:01<00:03, 44.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 67/195 [00:01<00:02, 42.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 72/195 [00:01<00:03, 40.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 77/195 [00:01<00:02, 39.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 81/195 [00:01<00:02, 39.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 85/195 [00:02<00:02, 39.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 89/195 [00:02<00:02, 37.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 93/195 [00:02<00:02, 37.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 97/195 [00:02<00:02, 37.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 102/195 [00:02<00:02, 38.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 106/195 [00:02<00:02, 38.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 111/195 [00:02<00:02, 40.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 116/195 [00:02<00:01, 42.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 121/195 [00:02<00:01, 43.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 126/195 [00:02<00:01, 44.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 131/195 [00:03<00:01, 44.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 136/195 [00:03<00:01, 44.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 141/195 [00:03<00:01, 45.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 146/195 [00:03<00:01, 45.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 151/195 [00:03<00:00, 45.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 156/195 [00:03<00:00, 44.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 161/195 [00:03<00:00, 44.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 166/195 [00:03<00:00, 44.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 171/195 [00:04<00:00, 42.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 176/195 [00:04<00:00, 41.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 181/195 [00:04<00:00, 39.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 186/195 [00:04<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 191/195 [00:04<00:00, 41.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 195/195 [00:04<00:00, 42.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 0.7861539125442505\n"
     ]
    }
   ],
   "source": [
    "def CVScore(test):\n",
    "    \n",
    "    scs = lambda row: abs((cosine_similarity(row[\"actual_embeddings\"], row[\"pred_embeddings\"])) ** 3)\n",
    "    \n",
    "    model = SentenceTransformer('/kaggle/input/sentence-t5-base-hf/sentence-t5-base')\n",
    "\n",
    "    test[\"actual_embeddings\"] = test[\"rewrite_prompt\"].progress_apply(lambda x: model.encode(x, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1))\n",
    "    test[\"pred_embeddings\"] = test[\"pred\"].progress_apply(lambda x: model.encode(x, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1))\n",
    "    \n",
    "    test[\"score\"] = test.apply(scs, axis=1)\n",
    "    \n",
    "    return np.mean(test['score'])[0][0]\n",
    "    \n",
    "print(f\"CV Score: {CVScore(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48947f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T09:31:39.360998Z",
     "iopub.status.busy": "2024-08-28T09:31:39.360721Z",
     "iopub.status.idle": "2024-08-28T09:31:41.074775Z",
     "shell.execute_reply": "2024-08-28T09:31:41.073826Z"
    },
    "papermill": {
     "duration": 1.730416,
     "end_time": "2024-08-28T09:31:41.076953",
     "exception": false,
     "start_time": "2024-08-28T09:31:39.346537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('test_df_gemma_7b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b06322",
   "metadata": {
    "papermill": {
     "duration": 0.013109,
     "end_time": "2024-08-28T09:31:41.103597",
     "exception": false,
     "start_time": "2024-08-28T09:31:41.090488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4516155,
     "sourceId": 7729151,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4516250,
     "sourceId": 7729275,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4811475,
     "sourceId": 9262098,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5606494,
     "sourceId": 9264977,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 194387999,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5391,
     "sourceId": 11373,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30666,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 454.522351,
   "end_time": "2024-08-28T09:31:45.905542",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-28T09:24:11.383191",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
